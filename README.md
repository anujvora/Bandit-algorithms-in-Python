# Bandit-algorithms-in-Python
Multi-armed bandits capture the essence of tradeoffs between exploration and exploitation while making decision in unknown environments. Some of the popular bandit algorithms have been coded in Python.

Currently implemented algorithms:

- Thompson Sampling
- $\epsilon-$ Thompson Sampling

TODO:
- $\epsilon-$ Greedy
- Upper Confidence Bound (UCB)
- Bayesian UCB
- Information Directed Sampling (IDS)
- Bayesian Information Directed Sampling (BIDS)